# @package _global_
num_workers: 8
batch_size: 256

trainer:
  accelerator: gpu
  devices: 1
  precision: "bf16-mixed"

network:
  n_down_blocks: [2, 2, 2]
  n_up_blocks: [2, 2, 2]
  dropout_rate: [0., 0., 0.]
  channel_mul: [2, 4, 8]

det_network:
  n_down_blocks: [2, 2, 2]
  n_up_blocks: [2, 2, 2]
  dropout_rate: [0., 0., 0.]
  channel_mul: [2, 4, 8]